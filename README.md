# RAG Audiovisual 2025 (Qdrant + Gemini)

**Objetivo**: Sistema RAG (Retrievalâ€‘Augmented Generation) que indexa el *Informe del Sector Audiovisual 2025* y permite hacer preguntas en espaÃ±ol usando **Qdrant** como base vectorial y **Google Gemini** como LLM. Incluye endpoints para consulta y **actualizaciÃ³n continua** de datos (upsert desde texto o PDF), mÃ©tricas y limpieza por fuente.

![alt text](pictures/image-2.png)
---

## ğŸ§­ Ãndice

- [Arquitectura](#arquitectura)
- [Requisitos](#requisitos)
- [Estructura del proyecto](#estructura-del-proyecto)
- [ConfiguraciÃ³n](#configuraciÃ³n)
- [Arranque rÃ¡pido](#arranque-rÃ¡pido)
- [Ingesta / actualizaciÃ³n de datos](#ingesta--actualizaciÃ³n-de-datos)
- [API (FastAPI)](#api-fastapi)
  - [/health](#get-health)
  - [/models](#get-models)
  - [/ask](#post-ask)
  - [/upsert](#post-upsert)
  - [/upsert_pdf](#post-upsert_pdf)
  - [/delete_by_source](#post-delete_by_source)
  - [/stats](#get-stats)
- [CÃ³mo funciona la recuperaciÃ³n](#cÃ³mo-funciona-la-recuperaciÃ³n)
- [SoluciÃ³n de problemas](#soluciÃ³n-de-problemas)

---

## Arquitectura

**Flujo**:

1. Usuario lanza una **pregunta** â†’ `POST /ask`.
2. La pregunta se **vectoriza** con `sentence-transformers`.
3. Qdrant realiza **bÃºsqueda semÃ¡ntica** (k alta) y el servicio hace **reâ€‘ranking local** por coseno.
4. Se forma un **contexto** con fragmentos topâ€‘k (y fuentes).
5. **Gemini** genera la respuesta **solo** con ese contexto (si no estÃ¡, lo indica).

**ActualizaciÃ³n**:

- `POST /upsert`: ingesta de texto (ya troceado o a trocear) con metadatos.
- `POST /upsert_pdf`: ingesta desde un PDF (multipart).
- `POST /delete_by_source`: limpieza de contenidos por `source`.
- `GET /stats`: conteos y diagnÃ³stico rÃ¡pido.

---

## Requisitos

- Python 3.10â€“3.12 (âš ï¸ En 3.14 algunas libs aÃºn estÃ¡n madurando)
- Docker (para Qdrant) y `docker compose`
- Cuenta de Google AI Studio y **GEMINI_API_KEY**

**Python**:

```bash
python -m venv .venv
# macOS / Linux
source .venv/bin/activate
# Windows (PowerShell)
# .venv\Scripts\Activate.ps1

pip install -r requirements.txt
```

**Qdrant** (local):

```bash
docker compose up -d    # levanta Qdrant con volumen en ./qdrant_data
```

---

## Estructura del proyecto

```text
.
â”œâ”€ .env                                          # variables locales 
â”œâ”€ .env.example                                  # plantilla de variables 
â”œâ”€ docker-compose.yaml                           # Qdrant local
â”œâ”€ Makefile                                      # atajos de desarrollo 
â”œâ”€ pictures/
â”‚  â”œâ”€ image.png                                  # ejemplo de peticiÃ³n a /ask
â”‚  â”œâ”€ image-1.png                                # ejemplo de respuesta de /ask
â”‚  â”œâ”€ image-2.png                                # UI de endpoints
â”‚  â””â”€ Qdrant.png                                 # interfaz en Qdrant 
â”œâ”€ qdrant_config/
â”‚  â””â”€ config.yaml                                # configuraciÃ³n avanzada 
â”œâ”€ qdrant_data/                                  # datos persistentes de Qdrant (se crea al arrancar)
â”œâ”€ data/
â”‚  â”œâ”€ raw/
â”‚  â”‚  â””â”€ informe_sector_audiovisual_2025.pdf
â”‚  â”œâ”€ interim/
â”‚  â”‚  â”œâ”€ informe_sector_audiovisual_2025.txt
â”‚  â”‚  â””â”€ informe_sector_audiovisual_2025.json
â”‚  â””â”€ processed/
â”‚     â””â”€ chunks.jsonl                             # trozos ya procesados (si se usa flujo offline)
â”œâ”€ scripts/
â”‚  â”œâ”€ create_qdrant_collection.py                 # crea/asegura colecciÃ³n + Ã­ndice text
â”‚  â”œâ”€ metadata_enricher.py                        # ejemplo de enriquecimiento de payload
â”‚  â”œâ”€ query_points.py                             # prueba de consultas a Qdrant
â”‚  â”œâ”€ reset_collection.py                         # recrea (borra datos)
â”‚  â””â”€ upsert_chunks.py                            # ingesta desde JSONL (offline)
â”œâ”€ src/informe_sector_audiovisual_2025/
â”‚  â”œâ”€ api_rag.py                                  # FastAPI: /ask, /upsert, /upsert_pdf, /delete_by_source, /stats
â”‚  â”œâ”€ chunking.py                                 # troceo configurable (tamaÃ±o, solape, normalizaciÃ³n)
â”‚  â”œâ”€ embeddings.py                               # carga y uso del modelo de embeddings
â”‚  â”œâ”€ ingest_pdf.py                               # extracciÃ³n de texto con PyMuPDF/pdfminer.six
â”‚  â”œâ”€ config.py                                   # utilidades de configuraciÃ³n
â”‚  â””â”€ __init__.py
â”œâ”€ pyproject.toml                                 # metadatos del proyecto (nombre, versiÃ³n) 
â”œâ”€ requirements.txt                               # dependencias de ejecuciÃ³n
â””â”€ docs/
   â””â”€ memoria-informe-audiovisual-2025.pdf        # memoria del proyecto

```

---

## ğŸ§° Scripts de procesamiento e indexado

Estos scripts permiten ejecutar el flujo **offline** paso a paso antes de usar la API.  
Cada uno puede lanzarse manualmente con `PYTHONPATH=src python scripts/<nombre>.py`.

| Orden | Script | DescripciÃ³n breve |
|:--:|:--|:--|
| **1ï¸âƒ£** | `ingest_pdf.py` | Extrae texto del PDF original y genera:<br>â†’ `data/interim/informe_sector_audiovisual_2025.json` (pÃ¡ginas)<br>â†’ `data/interim/informe_sector_audiovisual_2025.txt` (texto plano concatenado). |
| **2ï¸âƒ£** | `chunking.py` | Divide el texto plano en fragmentos (~1000 caracteres, con solape de 150). Crea `data/processed/chunks.jsonl`. |
| **3ï¸âƒ£** | `metadata_enricher.py` | Asocia cada fragmento con su nÃºmero de pÃ¡gina y aÃ±ade metadatos (`page`, `section`, `source`). Sobrescribe `chunks.jsonl` enriquecido. |
| **4ï¸âƒ£** | `create_qdrant_collection.py` | Crea (si no existe) la colecciÃ³n `audiovisual_2025` en Qdrant, con vector size y mÃ©trica `COSINE`. AÃ±ade un Ã­ndice `MatchText` sobre `text`. |
| **5ï¸âƒ£** | `upsert_chunks.py` | Inserta en Qdrant los chunks ya enriquecidos. Calcula embeddings, genera IDs deterministas y realiza `upsert`. |
| **6ï¸âƒ£** | `query_points.py` | Verifica la indexaciÃ³n consultando Qdrant con una frase de prueba. Devuelve textos mÃ¡s relevantes con su score. |
| **7ï¸âƒ£** | `reset_collection.py` *(opcional)* | Elimina y recrea la colecciÃ³n desde cero. Ãštil para reiniciar la base vectorial durante pruebas. |

ğŸ“Œ **Consejo**:  
Antes de lanzar la API FastAPI, asegÃºrate de haber ejecutado los pasos **1 â†’ 5**, para que la colecciÃ³n estÃ© lista y poblada.

---

## ConfiguraciÃ³n

Crea un `.env` en la raÃ­z (o copia desde `.env.example`):

```env
# Gemini
GEMINI_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
GEMINI_MODEL=models/gemini-2.5-flash

# Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=audiovisual_2025

# Embeddings
EMBEDDINGS_MODEL=intfloat/multilingual-e5-small
```

> Puedes listar modelos disponibles con `GET /models` y cambiar `GEMINI_MODEL` si lo deseas.

---

## Arranque rÃ¡pido

1) **Levantar Qdrant**

```bash
docker compose up -d
```

![alt text](pictures/Qdrant.png)

2) **Crear/asegurar la colecciÃ³n e Ã­ndice de texto**

```bash
PYTHONPATH=src python scripts/create_qdrant_collection.py
```

Este script crea la colecciÃ³n `audiovisual_2025` con distancia **COSINE** y un Ã­ndice de payload sobre el campo `text` para bÃºsquedas `MatchText`.

3) **Lanzar la API**

```bash
PYTHONPATH=src uvicorn informe_sector_audiovisual_2025.api_rag:app --reload
```

Abre `http://127.0.0.1:8000/docs` para la UI.

---

## Ingesta / actualizaciÃ³n de datos

### A) Upsert de **texto** (troceado automÃ¡tico)

```bash
curl -X POST "http://127.0.0.1:8000/upsert" \
  -H "Content-Type: application/json" \
  -d '{
        "text": "Este es un texto largo con datos que quiero indexar...",
        "source": "nota_prensa_2025",
        "max_chars": 1000,
        "overlap": 120
      }'
```

- Si pasas `text` (string), el servicio lo **trocea** y lo indexa.
- Si pasas `texts` (lista de trozos), los indexa tal cual.
- AÃ±ade metadatos Ãºtiles: `source`, `page`, `chunk_id`, `created_at`.

### B) Upsert desde **PDF** (multipart)
>
> Requiere `python-multipart` (incluido en `requirements.txt`).

```bash
curl -X POST "http://127.0.0.1:8000/upsert_pdf" \
  -F "file=@data/raw/informe_sector_audiovisual_2025.pdf" \
  -F "source=informe_sector_audiovisual_2025.pdf" \
  -F "max_chars=1000" \
  -F "overlap=120"
```

### C) Borrado por **source**

```bash
curl -X POST "http://127.0.0.1:8000/delete_by_source" \
  -H "Content-Type: application/json" \
  -d '{"source":"nota_prensa_2025"}'
```

### D) **EstadÃ­sticas**

```bash
curl "http://127.0.0.1:8000/stats"
```

---

## API (FastAPI)

### GET `/health`

Comprueba variables de entorno y acceso a Qdrant. **200 OK**:

```json
{
  "status": "ok",
  "gemini_key": true,
  "qdrant": true,
  "model": "models/gemini-2.5-flash"
}
```

### GET `/models`

Lista los modelos de Gemini que soportan `generateContent`.

### POST `/ask`

Consulta con recuperaciÃ³n + reâ€‘ranking + respuesta de Gemini **basada exclusivamente en el contexto**.

**Body**:

```json
{
  "question": "Â¿QuÃ© cuota de facturaciÃ³n tiene Madrid en el mercado de animaciÃ³n?",
  "top_k": 5,
  "filter_text": "animaciÃ³n Madrid",
  "debug": true
}
```

**UI**
![alt text](pictures/image.png)

**Ejemplo de respuesta**
![alt text](pictures/image-1.png)

### POST `/upsert`

Inserta/actualiza embeddings desde **texto**. Ver secciÃ³n [Ingesta](#ingesta--actualizaciÃ³n-de-datos).

### POST `/upsert_pdf`

Inserta/actualiza desde **PDF** (multipart). Ver secciÃ³n [Ingesta](#ingesta--actualizaciÃ³n-de-datos).

### POST `/delete_by_source`

Elimina puntos cuyo `payload.source` coincida. Ãštil para reemplazar informes/ notas obsoletas.

### GET `/stats`

Devuelve el nÃºmero de puntos y los recuentos por `source` para diagnÃ³stico rÃ¡pido.

---

## CÃ³mo funciona la recuperaciÃ³n

- **Embeddings**: `sentence-transformers intfloat/multilingual-e5-small` (configurable en `embeddings.py`) optimizado para espaÃ±ol, 384 dimensiones.
- **Qdrant**: distancia **COSINE**; se pide un `k` generoso para buen *recall* y se hace **reâ€‘ranking local** por coseno con el vector de la pregunta.
**Filtro semÃ¡ntico**: `filter_text` activa un `MatchText` sobre el campo `text` (Ã­ndice creado por `scripts/create_qdrant_collection.py`).
- **Prompting**: instrucciÃ³n en espaÃ±ol con *guardrail*: si la info **no estÃ¡** en el contexto, **lo dice**.

---

## SoluciÃ³n de problemas

- **Embeddings**: si hay errores al cargar el modelo, revisa embeddings.py y asegÃºrate de que `EMBEDDINGS_MODEL` estÃ¡ definido como `intfloat/multilingual-e5-small` en tu `.env`.
- **Modelos Gemini**: si recibes error de modelo, revisa `GET /models` y ajusta `GEMINI_MODEL` en `.env`.
- **VersiÃ³n de Python**: si estÃ¡s en 3.14 y alguna lib falla, usa 3.12 para mÃ¡xima compatibilidad.
- **ColecciÃ³n/Ã­ndice**: ejecuta `PYTHONPATH=src python scripts/create_qdrant_collection.py` para crear o recrear colecciÃ³n e Ã­ndice de texto.

---

## 11) AutorÃ­a

- Ana BelÃ©n Ballesteros Redondo  
  ğŸ”— [LinkedIn](https://www.linkedin.com/in/ana-belÃ©n-ballesteros-redondo/)

ğŸ“‘ **Memoria del proyecto:**  
[Visualizar PDF](docs/memoria-informe-audiovisual-2025.pdf) â€” documento completo de diseÃ±o, resultados y anÃ¡lisis.
